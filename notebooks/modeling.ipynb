{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "660fb4e6",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c44b8",
   "metadata": {},
   "source": [
    "## [1. Importing Packages and Methods](#1_importing_packages_and_methods)\n",
    "## [2. Importing Data and Labeling](#2_importing_data_and_labeling)\n",
    "## [3. Trading Bots Creation](#3_trading_bots_creations)\n",
    "- ### [3.1 Conditional Trading](#3_1_conditional_trading)\n",
    "    - #### [3.1.1 Conditional Trading Momentum - SMA](#3_1_1_conditional_trading_momentum_sma)\n",
    "    - #### [3.1.2 Conditional Bollinger Momentum](#3_1_2_conditional_bollinger_momentum)\n",
    "    - #### [3.1.3 Conditional Bollinger Contrarian](#3_1_3_conditional_bollinger_contrarian)\n",
    "- ### [3.2 Exponential Moving Average](#3_2_exponential_moving_average)\n",
    "    - #### [3.2.1 Exponential Momentum](#3_2_1_exponential_momentum)\n",
    "- ### [3.3 Double Rolling](#3_3_double_rolling)\n",
    "    - #### [3.3.1 SMA on EMA](#3_3_1_sma_on_ema)\n",
    "- ### [3.4 Heikin Ashi and Bollinger](#3_4_heikin_ashi_and_bollinger)\n",
    "    - #### [3.4.1 Heikin Ashi and Bollinger Momentum](#3_4_1_heikin_ashi_and_bollinger_momentum)\n",
    "- ### [QQ Graph](#qq_graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecb8cfa",
   "metadata": {},
   "source": [
    "## 1. Importing Packages and Methods<a id='1_importing_packages_and_methods'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "912db8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "\n",
    "## Import desired packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "import statsmodels.api as sm\n",
    "import gc\n",
    "\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fdd469",
   "metadata": {},
   "source": [
    "## 2. Importing Data and Labeling<a id='2_importing_data_and_labeling'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70f41b95",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 32\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Data augmentation\u001b[39;00m\n\u001b[1;32m     25\u001b[0m datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(\n\u001b[1;32m     26\u001b[0m     rotation_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m     27\u001b[0m     width_shift_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m\n\u001b[1;32m     31\u001b[0m )\n\u001b[0;32m---> 32\u001b[0m \u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Define model\u001b[39;00m\n\u001b[1;32m     35\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/preprocessing/image.py:2114\u001b[0m, in \u001b[0;36mImageDataGenerator.fit\u001b[0;34m(self, x, augment, rounds, seed)\u001b[0m\n\u001b[1;32m   2111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2112\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[0;32m-> 2114\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrescale:\n\u001b[1;32m   2116\u001b[0m     x \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrescale\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mcopy\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:959\u001b[0m, in \u001b[0;36mcopy\u001b[0;34m(a, order, subok)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_copy_dispatcher)\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(a, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m'\u001b[39m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;124;03m    Return an array copy of the given object.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    957\u001b[0m \n\u001b[1;32m    958\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 959\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load images and labels\n",
    "\n",
    "\n",
    "def load_images(folder_path, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".png\"):\n",
    "            image = Image.open(os.path.join(folder_path, filename)).resize((224, 224))\n",
    "            images.append(np.array(image))\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "folder_0 = \"/Users/liqingyang/Documents/GitHub/head_shoulder_bots/data/processed_data/non_hs\"\n",
    "folder_1 = \"/Users/liqingyang/Documents/GitHub/head_shoulder_bots/data/processed_data/hs\"\n",
    "\n",
    "images_0, labels_0 = load_images(folder_0, 0)\n",
    "images_1, labels_1 = load_images(folder_1, 1)\n",
    "\n",
    "images = np.array(images_0 + images_1)\n",
    "labels = np.array(labels_0 + labels_1)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    rescale=1./255\n",
    ")\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(datagen.flow(X_train, y_train, batch_size=32), validation_data=(X_test/255, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e5b52c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
